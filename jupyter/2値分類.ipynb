{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 10:53:27.221579: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-13 10:53:27.242379: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-13 10:53:27.242657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./enter_data_enter.csv')\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.604938272</th>\n",
       "      <th>0.597639568</th>\n",
       "      <th>0.571007066</th>\n",
       "      <th>0.571162357</th>\n",
       "      <th>0.568677692</th>\n",
       "      <th>0.596785465</th>\n",
       "      <th>0.609441727</th>\n",
       "      <th>0.584051557</th>\n",
       "      <th>0.578305769</th>\n",
       "      <th>0.574578772</th>\n",
       "      <th>...</th>\n",
       "      <th>0.587700908</th>\n",
       "      <th>0.58731268.1</th>\n",
       "      <th>0.587700908.1</th>\n",
       "      <th>0.587623263.2</th>\n",
       "      <th>0.58731268.2</th>\n",
       "      <th>0.587079742.6</th>\n",
       "      <th>0.586924451.3</th>\n",
       "      <th>0.587157388.2</th>\n",
       "      <th>0.587079742.7</th>\n",
       "      <th>0.587390325.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.486440</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.486193</td>\n",
       "      <td>0.485947</td>\n",
       "      <td>0.485947</td>\n",
       "      <td>0.486193</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>0.486440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>0.489152</td>\n",
       "      <td>0.489645</td>\n",
       "      <td>0.489645</td>\n",
       "      <td>0.489645</td>\n",
       "      <td>0.489398</td>\n",
       "      <td>0.489398</td>\n",
       "      <td>0.489152</td>\n",
       "      <td>0.488905</td>\n",
       "      <td>0.488659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.586031</td>\n",
       "      <td>0.586541</td>\n",
       "      <td>0.585521</td>\n",
       "      <td>0.586286</td>\n",
       "      <td>0.585776</td>\n",
       "      <td>0.584757</td>\n",
       "      <td>0.584757</td>\n",
       "      <td>0.583992</td>\n",
       "      <td>0.585011</td>\n",
       "      <td>0.584757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513638</td>\n",
       "      <td>0.537344</td>\n",
       "      <td>0.577109</td>\n",
       "      <td>0.616875</td>\n",
       "      <td>0.632934</td>\n",
       "      <td>0.616365</td>\n",
       "      <td>0.593168</td>\n",
       "      <td>0.589090</td>\n",
       "      <td>0.571756</td>\n",
       "      <td>0.531736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.566820</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>0.567373</td>\n",
       "      <td>0.567558</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>0.567373</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>0.567926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519263</td>\n",
       "      <td>0.519816</td>\n",
       "      <td>0.521659</td>\n",
       "      <td>0.522765</td>\n",
       "      <td>0.524055</td>\n",
       "      <td>0.525899</td>\n",
       "      <td>0.524977</td>\n",
       "      <td>0.522212</td>\n",
       "      <td>0.522396</td>\n",
       "      <td>0.526820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.424123</td>\n",
       "      <td>0.422145</td>\n",
       "      <td>0.422640</td>\n",
       "      <td>0.422145</td>\n",
       "      <td>0.421651</td>\n",
       "      <td>0.423628</td>\n",
       "      <td>0.423134</td>\n",
       "      <td>0.422640</td>\n",
       "      <td>0.423134</td>\n",
       "      <td>0.422145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432032</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>0.433020</td>\n",
       "      <td>0.431537</td>\n",
       "      <td>0.431043</td>\n",
       "      <td>0.430054</td>\n",
       "      <td>0.430549</td>\n",
       "      <td>0.430054</td>\n",
       "      <td>0.430549</td>\n",
       "      <td>0.430549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.390663</td>\n",
       "      <td>0.388206</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>0.380221</td>\n",
       "      <td>0.377764</td>\n",
       "      <td>0.378993</td>\n",
       "      <td>0.377150</td>\n",
       "      <td>0.375307</td>\n",
       "      <td>0.375307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192875</td>\n",
       "      <td>0.193489</td>\n",
       "      <td>0.193489</td>\n",
       "      <td>0.193489</td>\n",
       "      <td>0.195332</td>\n",
       "      <td>0.191032</td>\n",
       "      <td>0.191032</td>\n",
       "      <td>0.191646</td>\n",
       "      <td>0.191646</td>\n",
       "      <td>0.192875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.509108</td>\n",
       "      <td>0.508869</td>\n",
       "      <td>0.508150</td>\n",
       "      <td>0.508869</td>\n",
       "      <td>0.508869</td>\n",
       "      <td>0.509348</td>\n",
       "      <td>0.509827</td>\n",
       "      <td>0.509348</td>\n",
       "      <td>0.511026</td>\n",
       "      <td>0.510547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449185</td>\n",
       "      <td>0.436961</td>\n",
       "      <td>0.413710</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.437919</td>\n",
       "      <td>0.466683</td>\n",
       "      <td>0.498322</td>\n",
       "      <td>0.491611</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>0.494008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.113437</td>\n",
       "      <td>0.137070</td>\n",
       "      <td>0.277515</td>\n",
       "      <td>0.259959</td>\n",
       "      <td>0.185010</td>\n",
       "      <td>0.187711</td>\n",
       "      <td>0.184335</td>\n",
       "      <td>0.187711</td>\n",
       "      <td>0.183660</td>\n",
       "      <td>0.185010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.044564</td>\n",
       "      <td>0.054018</td>\n",
       "      <td>0.063471</td>\n",
       "      <td>0.066172</td>\n",
       "      <td>0.062120</td>\n",
       "      <td>0.050641</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.047265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071482</td>\n",
       "      <td>0.073716</td>\n",
       "      <td>0.069248</td>\n",
       "      <td>0.069993</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>0.069993</td>\n",
       "      <td>0.071482</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>0.071482</td>\n",
       "      <td>0.072226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040208</td>\n",
       "      <td>0.040208</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.042442</td>\n",
       "      <td>0.044676</td>\n",
       "      <td>0.049144</td>\n",
       "      <td>0.046910</td>\n",
       "      <td>0.045421</td>\n",
       "      <td>0.045421</td>\n",
       "      <td>0.047655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.068915</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.071114</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.068915</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.068915</td>\n",
       "      <td>0.068915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.024927</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.024194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.509559</td>\n",
       "      <td>0.510662</td>\n",
       "      <td>0.509559</td>\n",
       "      <td>0.510294</td>\n",
       "      <td>0.512868</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.512868</td>\n",
       "      <td>0.511029</td>\n",
       "      <td>0.511397</td>\n",
       "      <td>0.511029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590074</td>\n",
       "      <td>0.589706</td>\n",
       "      <td>0.588603</td>\n",
       "      <td>0.591176</td>\n",
       "      <td>0.592279</td>\n",
       "      <td>0.594118</td>\n",
       "      <td>0.594485</td>\n",
       "      <td>0.594485</td>\n",
       "      <td>0.596691</td>\n",
       "      <td>0.597059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows × 5120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.604938272  0.597639568  0.571007066  0.571162357  0.568677692  \\\n",
       "204     0.486933     0.486933     0.486440     0.486933     0.486193   \n",
       "400     0.586031     0.586541     0.585521     0.586286     0.585776   \n",
       "128     0.566820     0.567189     0.567189     0.567373     0.567558   \n",
       "743     0.424123     0.422145     0.422640     0.422145     0.421651   \n",
       "520     0.391892     0.390663     0.388206     0.385135     0.380221   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "698     0.509108     0.508869     0.508150     0.508869     0.508869   \n",
       "654     0.113437     0.137070     0.277515     0.259959     0.185010   \n",
       "2       0.071482     0.073716     0.069248     0.069993     0.070737   \n",
       "311     0.068915     0.070381     0.071114     0.073314     0.072581   \n",
       "722     0.509559     0.510662     0.509559     0.510294     0.512868   \n",
       "\n",
       "     0.596785465  0.609441727  0.584051557  0.578305769  0.574578772  ...  \\\n",
       "204     0.485947     0.485947     0.486193     0.488166     0.486440  ...   \n",
       "400     0.584757     0.584757     0.583992     0.585011     0.584757  ...   \n",
       "128     0.567189     0.567373     0.567189     0.567742     0.567926  ...   \n",
       "743     0.423628     0.423134     0.422640     0.423134     0.422145  ...   \n",
       "520     0.377764     0.378993     0.377150     0.375307     0.375307  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "698     0.509348     0.509827     0.509348     0.511026     0.510547  ...   \n",
       "654     0.187711     0.184335     0.187711     0.183660     0.185010  ...   \n",
       "2       0.069993     0.071482     0.070737     0.071482     0.072226  ...   \n",
       "311     0.070381     0.068915     0.070381     0.068915     0.068915  ...   \n",
       "722     0.514706     0.512868     0.511029     0.511397     0.511029  ...   \n",
       "\n",
       "     0.587700908  0.58731268.1  0.587700908.1  0.587623263.2  0.58731268.2  \\\n",
       "204     0.488166      0.489152       0.489645       0.489645      0.489645   \n",
       "400     0.513638      0.537344       0.577109       0.616875      0.632934   \n",
       "128     0.519263      0.519816       0.521659       0.522765      0.524055   \n",
       "743     0.432032      0.433515       0.433020       0.431537      0.431043   \n",
       "520     0.192875      0.193489       0.193489       0.193489      0.195332   \n",
       "..           ...           ...            ...            ...           ...   \n",
       "698     0.449185      0.436961       0.413710       0.422100      0.437919   \n",
       "654     0.034436      0.035787       0.044564       0.054018      0.063471   \n",
       "2       0.040208      0.040208       0.041698       0.042442      0.044676   \n",
       "311     0.028592      0.028592       0.024927       0.023460      0.020528   \n",
       "722     0.590074      0.589706       0.588603       0.591176      0.592279   \n",
       "\n",
       "     0.587079742.6  0.586924451.3  0.587157388.2  0.587079742.7  0.587390325.1  \n",
       "204       0.489398       0.489398       0.489152       0.488905       0.488659  \n",
       "400       0.616365       0.593168       0.589090       0.571756       0.531736  \n",
       "128       0.525899       0.524977       0.522212       0.522396       0.526820  \n",
       "743       0.430054       0.430549       0.430054       0.430549       0.430549  \n",
       "520       0.191032       0.191032       0.191646       0.191646       0.192875  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "698       0.466683       0.498322       0.491611       0.492330       0.494008  \n",
       "654       0.066172       0.062120       0.050641       0.043889       0.047265  \n",
       "2         0.049144       0.046910       0.045421       0.045421       0.047655  \n",
       "311       0.021994       0.022727       0.023460       0.023460       0.024194  \n",
       "722       0.594118       0.594485       0.594485       0.596691       0.597059  \n",
       "\n",
       "[826 rows x 5120 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test  = df.iloc[:,1:]\n",
    "x_lavel = df.iloc[:,0]\n",
    "\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(826, 5120)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x_test = np.array(x_test)\n",
    "_x_lavel = np.array(x_lavel)\n",
    "\n",
    "_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:0,y_one_hot:[1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "x_one_hot = np_utils.to_categorical(x_lavel)\n",
    "print(f\"y:{x_lavel[0]},y_one_hot:{x_one_hot[0]}\")\n",
    "x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 教師データとテストデータに分割\n",
    "x_train, x_test, y_train, y_test= train_test_split(x_test, x_one_hot, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "# モデルの作成\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=5120))# 入力層5120ノード, 隠れ層に2ノード, 全結合\n",
    "model.add(Activation(\"sigmoid\"))    # 活性化関数 sigmoid relu\n",
    "model.add(Dense(2))                 # 出力層2ノード,全結合\n",
    "model.add(Activation(\"softmax\"))    # sigmoid softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",   # 誤差関数 binary_crossentropy categorical_crossentropy\n",
    "              optimizer=Adam(learning_rate=0.001),     # 最適化手法adam sgd\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7348\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7348\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7348\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7348\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7348\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7348\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7348\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7348\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7348\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7348\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7348\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7348\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7348\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7348\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7348\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7348\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7348\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7348\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7348\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7348\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7348\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7348\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7348\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7348\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7379\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7348\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7409\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7424\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7439\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7439\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7455\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7424\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7455\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7455\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7455\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7439\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7439\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7470\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7455\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7455\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7439\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7455\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7455\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7455\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7485\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7455\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7470\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7455\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7455\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7470\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7485\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7470\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7485\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7515\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7515\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7515\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7530\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7470\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7530\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7515\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7576\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7530\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7561\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7591\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7576\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7576\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7576\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7576\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7591\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7591\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7576\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7606\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7606\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7591\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7636\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7606\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7606\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7621\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7591\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7621\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7621\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7621\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7606\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7621\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7621\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7621\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7621\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7621\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7682\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7621\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7621\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7652\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7652\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7667\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7636\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7652\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7621\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7682\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7652\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7636\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7667\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7636\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7652\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7636\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7652\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7697\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7636\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7667\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7621\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7697\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7712\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7697\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7697\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7712\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7636\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7667\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7682\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7697\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7697\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7712\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7682\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7697\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7712\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7697\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7697\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7697\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7697\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7697\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7712\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7727\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7727\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7712\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7727\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7712\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7727\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7727\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7712\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7727\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7742\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7712\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7742\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7712\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7727\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7742\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7727\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7758\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7742\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7727\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7758\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7727\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7742\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7742\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7758\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7742\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7742\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7742\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7742\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7758\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7758\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7758\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7758\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7758\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7727\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7758\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7742\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7758\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7742\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7758\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7742\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7742\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7758\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7758\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7758\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7742\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7758\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7758\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7742\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7758\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7758\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7758\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7758\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7758\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7758\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7758\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7758\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7742\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7758\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7758\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7758\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7742\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7758\n"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "# 約数 1　2　4　3221　6442　12884\n",
    "# 1　2　4　5　8　10　16　20　32　40　64　80　128　160　256　320　512　640　1024　1280　2560　5120\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=32) # 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4ce025f3d0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"accuracy\"], label=\"acc\")\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6988\n",
      "Test score 0.6570118069648743\n",
      "Test accuracy 0.6987951993942261\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Test score\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('enter_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6570118069648743, 0.6987951993942261]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "load_model = keras.models.load_model('enter_model.h5')\n",
    "\n",
    "load_model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.717963   0.28203708]\n",
      "[0.71728754 0.2827124 ]\n",
      "[0.8484999  0.15150003]\n",
      "[0.79762185 0.20237805]\n",
      "[0.818572 0.181428]\n"
     ]
    }
   ],
   "source": [
    "hoge = load_model.predict(x_test, batch_size=32, verbose=0, steps=None)\n",
    "\n",
    "for i in range(160):\n",
    "    if hoge[i][0] >= 0.6:\n",
    "        print(hoge[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.5103 - acc: 0.7911 - val_loss: 0.4016 - val_acc: 0.8628\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.3110 - acc: 0.9031 - val_loss: 0.3085 - val_acc: 0.8870\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.2309 - acc: 0.9235 - val_loss: 0.2803 - val_acc: 0.8908\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.1795 - acc: 0.9428 - val_loss: 0.2735 - val_acc: 0.8893\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.1475 - acc: 0.9526 - val_loss: 0.2788 - val_acc: 0.8890\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.1185 - acc: 0.9638 - val_loss: 0.3330 - val_acc: 0.8764\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.1005 - acc: 0.9703 - val_loss: 0.3055 - val_acc: 0.8838\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0818 - acc: 0.9773 - val_loss: 0.3344 - val_acc: 0.8769\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0696 - acc: 0.9814 - val_loss: 0.3607 - val_acc: 0.8800\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0547 - acc: 0.9873 - val_loss: 0.3776 - val_acc: 0.8785\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0453 - acc: 0.9895 - val_loss: 0.4035 - val_acc: 0.8765\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0353 - acc: 0.9930 - val_loss: 0.4437 - val_acc: 0.8766\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0269 - acc: 0.9956 - val_loss: 0.4637 - val_acc: 0.8747\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0212 - acc: 0.9968 - val_loss: 0.4877 - val_acc: 0.8714\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0162 - acc: 0.9977 - val_loss: 0.6080 - val_acc: 0.8625\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0115 - acc: 0.9993 - val_loss: 0.5778 - val_acc: 0.8698\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0116 - acc: 0.9979 - val_loss: 0.5906 - val_acc: 0.8702\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0054 - acc: 0.9998 - val_loss: 0.6204 - val_acc: 0.8639\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0083 - acc: 0.9984 - val_loss: 0.6419 - val_acc: 0.8676\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s - loss: 0.0031 - acc: 0.9998 - val_loss: 0.6796 - val_acc: 0.8683\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_acc', 'acc', 'val_loss', 'loss'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b00fd44d87c528ae857fa86a0704c55dde2665c80c2cbc47954fac982538b4ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
