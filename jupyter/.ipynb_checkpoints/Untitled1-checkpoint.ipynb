{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2faad08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 19:42:58.807593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-03 19:42:58.807665: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f343d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.19607843, 0.05882353, 0.        ],\n",
       "         [0.20784314, 0.05490196, 0.        ],\n",
       "         [0.22745098, 0.04705882, 0.        ],\n",
       "         ...,\n",
       "         [0.22745098, 0.14117648, 0.        ],\n",
       "         [0.25882354, 0.2       , 0.        ],\n",
       "         [0.30588236, 0.27058825, 0.0627451 ]],\n",
       "\n",
       "        [[0.50980395, 0.42745098, 0.27058825],\n",
       "         [0.52156866, 0.42352942, 0.26666668],\n",
       "         [0.5372549 , 0.41568628, 0.2627451 ],\n",
       "         ...,\n",
       "         [0.50980395, 0.47058824, 0.26666668],\n",
       "         [0.52156866, 0.5058824 , 0.2901961 ],\n",
       "         [0.5137255 , 0.52156866, 0.30588236]],\n",
       "\n",
       "        [[0.84313726, 0.8745098 , 0.6431373 ],\n",
       "         [0.85490197, 0.87058824, 0.63529414],\n",
       "         [0.87058824, 0.8627451 , 0.627451  ],\n",
       "         ...,\n",
       "         [0.8039216 , 0.87058824, 0.627451  ],\n",
       "         [0.78431374, 0.8666667 , 0.627451  ],\n",
       "         [0.72156864, 0.8235294 , 0.58431375]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1882353 , 0.69803923, 0.44705883],\n",
       "         [0.1882353 , 0.69803923, 0.44705883],\n",
       "         [0.19215687, 0.7019608 , 0.4509804 ],\n",
       "         ...,\n",
       "         [0.2       , 0.7058824 , 0.44313726],\n",
       "         [0.19607843, 0.7019608 , 0.44705883],\n",
       "         [0.1882353 , 0.69803923, 0.44705883]],\n",
       "\n",
       "        [[0.20392157, 0.7137255 , 0.4627451 ],\n",
       "         [0.20392157, 0.7137255 , 0.4627451 ],\n",
       "         [0.20784314, 0.7176471 , 0.46666667],\n",
       "         ...,\n",
       "         [0.21568628, 0.72156864, 0.45882353],\n",
       "         [0.21176471, 0.7176471 , 0.4627451 ],\n",
       "         [0.20392157, 0.70980394, 0.45882353]],\n",
       "\n",
       "        [[0.21960784, 0.7294118 , 0.47843137],\n",
       "         [0.22352941, 0.73333335, 0.48235294],\n",
       "         [0.22745098, 0.7372549 , 0.4862745 ],\n",
       "         ...,\n",
       "         [0.23529412, 0.7411765 , 0.47843137],\n",
       "         [0.22745098, 0.73333335, 0.48235294],\n",
       "         [0.21960784, 0.72156864, 0.47058824]]],\n",
       "\n",
       "\n",
       "       [[[0.23137255, 0.0627451 , 0.        ],\n",
       "         [0.23529412, 0.05882353, 0.        ],\n",
       "         [0.24313726, 0.05882353, 0.        ],\n",
       "         ...,\n",
       "         [0.23529412, 0.06666667, 0.        ],\n",
       "         [0.23529412, 0.06666667, 0.        ],\n",
       "         [0.21960784, 0.05098039, 0.        ]],\n",
       "\n",
       "        [[0.5372549 , 0.42352942, 0.27058825],\n",
       "         [0.54509807, 0.41960785, 0.27058825],\n",
       "         [0.5529412 , 0.41960785, 0.26666668],\n",
       "         ...,\n",
       "         [0.54509807, 0.42745098, 0.2627451 ],\n",
       "         [0.54509807, 0.42745098, 0.2627451 ],\n",
       "         [0.5372549 , 0.42352942, 0.26666668]],\n",
       "\n",
       "        [[0.8627451 , 0.8666667 , 0.6392157 ],\n",
       "         [0.87058824, 0.85882354, 0.6392157 ],\n",
       "         [0.88235295, 0.8627451 , 0.63529414],\n",
       "         ...,\n",
       "         [0.8745098 , 0.87058824, 0.627451  ],\n",
       "         [0.8745098 , 0.87058824, 0.627451  ],\n",
       "         [0.8784314 , 0.8745098 , 0.6313726 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.20784314, 0.7019608 , 0.4509804 ],\n",
       "         [0.20784314, 0.7019608 , 0.4509804 ],\n",
       "         [0.21176471, 0.7058824 , 0.45490196],\n",
       "         ...,\n",
       "         [0.20784314, 0.7058824 , 0.44313726],\n",
       "         [0.20392157, 0.7019608 , 0.4392157 ],\n",
       "         [0.21176471, 0.70980394, 0.44705883]],\n",
       "\n",
       "        [[0.22352941, 0.7176471 , 0.46666667],\n",
       "         [0.22352941, 0.7176471 , 0.46666667],\n",
       "         [0.22745098, 0.72156864, 0.47058824],\n",
       "         ...,\n",
       "         [0.22352941, 0.72156864, 0.45882353],\n",
       "         [0.21960784, 0.7176471 , 0.45490196],\n",
       "         [0.22745098, 0.7254902 , 0.4627451 ]],\n",
       "\n",
       "        [[0.23921569, 0.73333335, 0.48235294],\n",
       "         [0.24313726, 0.7372549 , 0.4862745 ],\n",
       "         [0.24705882, 0.7411765 , 0.49019608],\n",
       "         ...,\n",
       "         [0.24313726, 0.7411765 , 0.47843137],\n",
       "         [0.23921569, 0.7372549 , 0.4745098 ],\n",
       "         [0.24313726, 0.7411765 , 0.47843137]]],\n",
       "\n",
       "\n",
       "       [[[0.23529412, 0.06666667, 0.        ],\n",
       "         [0.23137255, 0.0627451 , 0.        ],\n",
       "         [0.22352941, 0.05490196, 0.        ],\n",
       "         ...,\n",
       "         [0.18431373, 0.23529412, 0.05490196],\n",
       "         [0.1882353 , 0.22352941, 0.03921569],\n",
       "         [0.23137255, 0.25490198, 0.07058824]],\n",
       "\n",
       "        [[0.54901963, 0.43137255, 0.26666668],\n",
       "         [0.54509807, 0.43137255, 0.26666668],\n",
       "         [0.5372549 , 0.42352942, 0.2627451 ],\n",
       "         ...,\n",
       "         [0.43529412, 0.52156866, 0.3254902 ],\n",
       "         [0.43137255, 0.49803922, 0.30588236],\n",
       "         [0.4392157 , 0.49803922, 0.30588236]],\n",
       "\n",
       "        [[0.88235295, 0.8784314 , 0.63529414],\n",
       "         [0.88235295, 0.8784314 , 0.63529414],\n",
       "         [0.8745098 , 0.87058824, 0.627451  ],\n",
       "         ...,\n",
       "         [0.7019608 , 0.85882354, 0.6431373 ],\n",
       "         [0.6901961 , 0.83137256, 0.61960787],\n",
       "         [0.6627451 , 0.7921569 , 0.58431375]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.20392157, 0.69803923, 0.44705883],\n",
       "         [0.20784314, 0.7019608 , 0.4509804 ],\n",
       "         [0.21568628, 0.70980394, 0.45882353],\n",
       "         ...,\n",
       "         [0.21568628, 0.7137255 , 0.4509804 ],\n",
       "         [0.21568628, 0.7137255 , 0.4509804 ],\n",
       "         [0.21568628, 0.7137255 , 0.4509804 ]],\n",
       "\n",
       "        [[0.21960784, 0.7137255 , 0.4627451 ],\n",
       "         [0.22352941, 0.7176471 , 0.46666667],\n",
       "         [0.23137255, 0.7254902 , 0.4745098 ],\n",
       "         ...,\n",
       "         [0.22745098, 0.7254902 , 0.4627451 ],\n",
       "         [0.22745098, 0.7254902 , 0.4627451 ],\n",
       "         [0.22745098, 0.7254902 , 0.4627451 ]],\n",
       "\n",
       "        [[0.23921569, 0.73333335, 0.48235294],\n",
       "         [0.23921569, 0.73333335, 0.48235294],\n",
       "         [0.24705882, 0.7411765 , 0.49019608],\n",
       "         ...,\n",
       "         [0.23921569, 0.7372549 , 0.4745098 ],\n",
       "         [0.23921569, 0.7372549 , 0.4745098 ],\n",
       "         [0.23921569, 0.7372549 , 0.4745098 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.22352941, 0.04705882, 0.        ],\n",
       "         [0.21960784, 0.04313726, 0.        ],\n",
       "         [0.21568628, 0.03921569, 0.        ],\n",
       "         ...,\n",
       "         [0.2784314 , 0.1882353 , 0.        ],\n",
       "         [0.22352941, 0.11764706, 0.        ],\n",
       "         [0.18431373, 0.0627451 , 0.        ]],\n",
       "\n",
       "        [[0.53333336, 0.4117647 , 0.27450982],\n",
       "         [0.5294118 , 0.40784314, 0.27450982],\n",
       "         [0.5254902 , 0.40392157, 0.27058825],\n",
       "         ...,\n",
       "         [0.5176471 , 0.47843137, 0.25882354],\n",
       "         [0.50980395, 0.4509804 , 0.2627451 ],\n",
       "         [0.49803922, 0.42745098, 0.27058825]],\n",
       "\n",
       "        [[0.8627451 , 0.85490197, 0.654902  ],\n",
       "         [0.85882354, 0.85490197, 0.6509804 ],\n",
       "         [0.85490197, 0.8509804 , 0.64705884],\n",
       "         ...,\n",
       "         [0.75686276, 0.81960785, 0.58431375],\n",
       "         [0.8117647 , 0.85882354, 0.62352943],\n",
       "         [0.8392157 , 0.8745098 , 0.6431373 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1764706 , 0.69411767, 0.46666667],\n",
       "         [0.1764706 , 0.69411767, 0.46666667],\n",
       "         [0.1764706 , 0.69411767, 0.46666667],\n",
       "         ...,\n",
       "         [0.18039216, 0.69803923, 0.47058824],\n",
       "         [0.18039216, 0.69803923, 0.47058824],\n",
       "         [0.1764706 , 0.69411767, 0.46666667]],\n",
       "\n",
       "        [[0.1882353 , 0.7058824 , 0.47843137],\n",
       "         [0.1882353 , 0.7058824 , 0.47843137],\n",
       "         [0.1882353 , 0.7058824 , 0.47843137],\n",
       "         ...,\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         [0.1882353 , 0.7058824 , 0.47843137]],\n",
       "\n",
       "        [[0.2       , 0.7176471 , 0.49019608],\n",
       "         [0.2       , 0.7176471 , 0.49019608],\n",
       "         [0.2       , 0.7176471 , 0.49019608],\n",
       "         ...,\n",
       "         [0.21176471, 0.7294118 , 0.5019608 ],\n",
       "         [0.21176471, 0.7294118 , 0.5019608 ],\n",
       "         [0.2       , 0.7176471 , 0.49019608]]],\n",
       "\n",
       "\n",
       "       [[[0.2       , 0.06666667, 0.        ],\n",
       "         [0.1882353 , 0.0627451 , 0.        ],\n",
       "         [0.15686275, 0.05490196, 0.        ],\n",
       "         ...,\n",
       "         [0.21960784, 0.04705882, 0.        ],\n",
       "         [0.21960784, 0.04705882, 0.        ],\n",
       "         [0.21568628, 0.04313726, 0.        ]],\n",
       "\n",
       "        [[0.5254902 , 0.43137255, 0.26666668],\n",
       "         [0.5176471 , 0.43137255, 0.27450982],\n",
       "         [0.49019608, 0.42745098, 0.2784314 ],\n",
       "         ...,\n",
       "         [0.53333336, 0.41568628, 0.27058825],\n",
       "         [0.5372549 , 0.41568628, 0.27450982],\n",
       "         [0.5294118 , 0.4117647 , 0.27058825]],\n",
       "\n",
       "        [[0.87058824, 0.8666667 , 0.627451  ],\n",
       "         [0.87058824, 0.8784314 , 0.64705884],\n",
       "         [0.85490197, 0.8784314 , 0.6627451 ],\n",
       "         ...,\n",
       "         [0.87058824, 0.8627451 , 0.6431373 ],\n",
       "         [0.8745098 , 0.8666667 , 0.64705884],\n",
       "         [0.8666667 , 0.85882354, 0.6392157 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.17254902, 0.6901961 , 0.4627451 ],\n",
       "         [0.17254902, 0.6901961 , 0.4627451 ],\n",
       "         [0.17254902, 0.6901961 , 0.4627451 ],\n",
       "         ...,\n",
       "         [0.17254902, 0.6901961 , 0.4627451 ],\n",
       "         [0.17254902, 0.6901961 , 0.4627451 ],\n",
       "         [0.17254902, 0.6901961 , 0.4627451 ]],\n",
       "\n",
       "        [[0.18431373, 0.7019608 , 0.4745098 ],\n",
       "         [0.18431373, 0.7019608 , 0.4745098 ],\n",
       "         [0.18431373, 0.7019608 , 0.4745098 ],\n",
       "         ...,\n",
       "         [0.18431373, 0.7019608 , 0.4745098 ],\n",
       "         [0.18431373, 0.7019608 , 0.4745098 ],\n",
       "         [0.18431373, 0.7019608 , 0.4745098 ]],\n",
       "\n",
       "        [[0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         ...,\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ],\n",
       "         [0.19607843, 0.7137255 , 0.4862745 ]]],\n",
       "\n",
       "\n",
       "       [[[0.0627451 , 0.14901961, 0.        ],\n",
       "         [0.1882353 , 0.28627452, 0.10588235],\n",
       "         [0.31764707, 0.41960785, 0.23529412],\n",
       "         ...,\n",
       "         [0.22745098, 0.05490196, 0.        ],\n",
       "         [0.22745098, 0.05490196, 0.        ],\n",
       "         [0.21568628, 0.04313726, 0.        ]],\n",
       "\n",
       "        [[0.3647059 , 0.48235294, 0.30588236],\n",
       "         [0.40392157, 0.5294118 , 0.34509805],\n",
       "         [0.4392157 , 0.57254905, 0.38039216],\n",
       "         ...,\n",
       "         [0.5372549 , 0.41960785, 0.27058825],\n",
       "         [0.5372549 , 0.41960785, 0.27058825],\n",
       "         [0.5294118 , 0.40784314, 0.26666668]],\n",
       "\n",
       "        [[0.69411767, 0.8784314 , 0.69411767],\n",
       "         [0.627451  , 0.81960785, 0.627451  ],\n",
       "         [0.5529412 , 0.75686276, 0.54901963],\n",
       "         ...,\n",
       "         [0.8627451 , 0.85882354, 0.6392157 ],\n",
       "         [0.8627451 , 0.85882354, 0.6392157 ],\n",
       "         [0.8627451 , 0.85490197, 0.63529414]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1764706 , 0.69411767, 0.45882353],\n",
       "         [0.1764706 , 0.69411767, 0.45882353],\n",
       "         [0.17254902, 0.6901961 , 0.45490196],\n",
       "         ...,\n",
       "         [0.18039216, 0.69803923, 0.4627451 ],\n",
       "         [0.18039216, 0.69803923, 0.4627451 ],\n",
       "         [0.18039216, 0.69803923, 0.4627451 ]],\n",
       "\n",
       "        [[0.19215687, 0.70980394, 0.4745098 ],\n",
       "         [0.19215687, 0.70980394, 0.4745098 ],\n",
       "         [0.18431373, 0.7019608 , 0.46666667],\n",
       "         ...,\n",
       "         [0.19215687, 0.70980394, 0.4745098 ],\n",
       "         [0.19215687, 0.70980394, 0.4745098 ],\n",
       "         [0.19607843, 0.7137255 , 0.47843137]],\n",
       "\n",
       "        [[0.20784314, 0.7254902 , 0.49019608],\n",
       "         [0.20784314, 0.7254902 , 0.49019608],\n",
       "         [0.19607843, 0.7137255 , 0.47843137],\n",
       "         ...,\n",
       "         [0.20392157, 0.72156864, 0.4862745 ],\n",
       "         [0.20392157, 0.72156864, 0.4862745 ],\n",
       "         [0.21176471, 0.7294118 , 0.49411765]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "f = pd.read_csv('./train_images.csv',header=1)\n",
    "x_lavel  = f.iloc[:,1:]\n",
    "x_test = f.iloc[:,0]\n",
    "_x_test = np.array(x_test)\n",
    "_x_lavel = np.array(x_lavel)\n",
    "\n",
    "train_image = []\n",
    "train_label = []\n",
    "check_image = []\n",
    "\n",
    "for line in _x_test:\n",
    "    line = line.rstrip()\n",
    "    l = line.split()\n",
    "    # データを読み込んで28x28に縮小\n",
    "    img = Image.open(l[0])\n",
    "    img = img.resize((32, 32))\n",
    "    # 一列にした後、0-1のfloat値にする\n",
    "    _img = np.asarray(img)\n",
    "    \n",
    "    train_image.append(_img.astype(np.float32)/255.0)\n",
    "    check_image.append(_img)\n",
    "    # ラベルを1-of-k方式で用意する\n",
    "    #tmp = np.zeros(4)\n",
    "    #tmp[int(l[1])] = 1\n",
    "    #train_label.append(tmp)\n",
    "# numpy形式に変換\n",
    "train_image = np.asarray(train_image)\n",
    "\n",
    "\n",
    "train_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65df4b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "x_one_hot = np_utils.to_categorical(_x_lavel)\n",
    "x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12399636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 教師データとテストデータに分割\n",
    "x_train, x_test, y_train, y_test= train_test_split(train_image, x_one_hot, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ea2f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,3,input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32,3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(1.0))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "adam = Adam(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fee84b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15bfc0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              1639424   \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,707,042\n",
      "Trainable params: 1,707,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "704f57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"dropout_5\" (type Dropout).\n    \n    `rate` must be a scalar tensor or a float in the range [0, 1). Received: rate=1.0\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 1024), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"dropout_5\" (type Dropout).\n    \n    `rate` must be a scalar tensor or a float in the range [0, 1). Received: rate=1.0\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 1024), dtype=float32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc94202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
